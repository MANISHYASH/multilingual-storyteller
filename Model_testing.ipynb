{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqmIApElDzW_",
        "outputId": "e3370a66-85df-4c51-e6d0-d0ba136b6a29"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Set the Hugging Face API URL and your token\n",
        "API_URL = \"https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-one-mmt\"  # Alternative model\n",
        "\n",
        "HUGGINGFACE_TOKEN = \"GENERATE YOUR TOKEN IN HUGGINGFACE\"  # Replace with your actual token\n",
        "headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_TOKEN}\"}\n",
        "\n",
        "# Define the text to be translated (Tamil to English)\n",
        "text = \"செயற்கை நுண்ணறிவு\"\n",
        "payload = {\"inputs\": text}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "# Check the response status and process the result\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    translated_text = result[0]['generated_text']\n",
        "    print(\"Translated Text:\", translated_text)\n",
        "else:\n",
        "    print(f\"Error {response.status_code}: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjdmjZBwNO-e",
        "outputId": "ccdf27b7-347a-46b7-e638-e24340494c71"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Set the Groq API URL and token\n",
        "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "GROQ_TOKEN = \"GENERATE YOUR API KEY FOR GROQ\"  # Replace with your actual token\n",
        "headers = {\"Authorization\": f\"Bearer {GROQ_TOKEN}\"}\n",
        "\n",
        "# Define the message for text generation\n",
        "messages = [{\"role\": \"user\", \"content\": \"Write a short story about a cat.\"}]\n",
        "\n",
        "# Create the payload\n",
        "payload = {\n",
        "    \"model\": \"mixtral-8x7b-32768\",  # Replace with the correct model name if available\n",
        "    \"messages\": messages,\n",
        "    \"max_tokens\": 100,  # Adjust as needed\n",
        "}\n",
        "\n",
        "# Make the request to the API\n",
        "response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the response\n",
        "    result = response.json()\n",
        "    generated_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "    print(\"Generated Text:\", generated_text)\n",
        "else:\n",
        "    print(f\"Error {response.status_code}: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fVIv7ifR1g",
        "outputId": "ea7db72c-8eda-42d4-8338-b0f93904e6e9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Set the API URL and the Hugging Face token\n",
        "API_URL = \"https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4\"\n",
        "HUGGINGFACE_TOKEN = \"GENERATE YOUR TOKEN IN HUGGINGFACE\"\n",
        "headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_TOKEN}\"}\n",
        "\n",
        "def query(payload):\n",
        "    try:\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "        # Log the status code and content type to help debug\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        content_type = response.headers.get('Content-Type')\n",
        "        print(f\"Content-Type: {content_type}\")\n",
        "\n",
        "        # If the response is an image, return the raw image data\n",
        "        if response.status_code == 200:\n",
        "            if 'image' in content_type:\n",
        "                return response.content  # Return raw image data\n",
        "            else:\n",
        "                # Log the raw response if it's not an image\n",
        "                print(f\"Raw Response: {response.text}\")\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Input text prompt for generating the image\n",
        "text_prompt = \"Create an image of a futuristic robot interacting with humans in a modern city, showcasing advanced AI technology\"\n",
        "\n",
        "# Payload for the API request\n",
        "data = {\n",
        "    \"inputs\": text_prompt\n",
        "}\n",
        "\n",
        "# Query the API with the text prompt\n",
        "image_data = query(data)\n",
        "\n",
        "# If the response contains image data, display it\n",
        "if image_data:\n",
        "    try:\n",
        "        image = Image.open(BytesIO(image_data))  # Convert raw bytes to image\n",
        "        image.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to open image: {e}\")\n",
        "else:\n",
        "    print(\"Failed to generate or retrieve the image.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
